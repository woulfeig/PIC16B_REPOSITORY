[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome! Here I will be documenting my journey through PIC 16B.\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/HW0-Data Visualization/index.html",
    "href": "posts/HW0-Data Visualization/index.html",
    "title": "Data Visualization",
    "section": "",
    "text": "There are many different ways to model and display a set of data. Using the Plotly library, we have the ability to make histographes, boxplots, and more. Plotly makes graphing and modelling data sets very simple and straighforward. In general, you start with calling the type of figure you would like to create and then manually selecting which customization you need for the specific plot.\n\n\n\nFor simplicity sake, today we will start with developing scatterplots. Before we start making our graph, we must download and organize our data. The easiest way to complete this step is by using panda operations as seen below. Today, we will be using the Palmer Penguin data set that analyzes the differences between three different species of penguins. In order to use this data sheet, we must ensure that we have the file downloaded to the same folder as our Jupyter Notebook. Please run the code cell below to upload the needed data.\n\nimport pandas as pd\nfilename = \"palmer_penguins.csv\"\npenguins = pd.read_csv(filename)\npenguins = penguins.dropna(subset = [\"Body Mass (g)\", \"Sex\"])\npenguins[\"Species\"] = penguins[\"Species\"].str.split().str.get(0)\npenguins = penguins[penguins[\"Sex\"] != \".\"]\n\ncols = [\"Species\", \"Island\", \"Sex\", \"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\"]\npenguins = penguins[cols]\n\nAfter we have downloaded our data set, we must import Plotly in order to make our visualizations. Plotly is a useful tool that can be used to create different types of graphs.\n\nimport plotly\n\nNext, we will create a visualization labeled “fig” and use our Plotly commands to organize our data. For this plot, we will see how the length and depth of the culmen vary for different species of penguins. The culmen describes the upper ridge of a penguin’s bill. Researches describe the culmen using depth and length.\nWe use the second and third lines of code to make the final plot visible to a blog user. If you are just planning on creating figures in your notebook, please only use the first line to import the necessary tools to create and customize the plot. We call our scatterplot in the fifth line of code. In the event that you are making a different type of plot, you would set “fig” equal to a different keyword. Within our “()” we will label our x and y axis, change dot color based on the species of penguin, and designate the size of the graph.\nIn the second to last line of code, we add extra customizations to the layout of the plot itself. By using these commands, we can decrease the amount of whitespace of our graph. Finally, we can see our final scatterplot using the last line of code.\n\nfrom plotly import express as px\nimport plotly.io as pio\npio.renderers.default='iframe'\n\nfig = px.scatter(data_frame = penguins,\n                 x = \"Culmen Length (mm)\",\n                 y = \"Culmen Depth (mm)\",\n                 color = \"Species\",\n                 width = 500,\n                 height = 300,\n                )\n\n\nfig.update_layout(margin={\"r\":0, \"t\":0, \"l\":0, \"b\":0})\n\nfig.show()\n \n\n\n\n\nIn all, scatterplots through Plotly are extremely customizable and only require basic calls. Plotly can be used for many different data sets and model many different ideas in a variety of forms.\n\n\n\nPlotly also has the ability to create more detailed scatterplots. For example, we can create facets within our scatterplots. Facets are smaller scatterplots that can add additional details to our visualizations. Similar to our above scatterplot, we will be comparing culmen measurements amoungest different species of penguins. However, we will further our understanding by creating facets that show the recorded culmen data in specific plots for female and male penguins.\nWe set up our plot in a relatively similar way to the demonstration above. The extra customizations will allow our graph to appear in two smaller sets.\n\nfig = px.scatter(data_frame = penguins,\n                 x = \"Culmen Length (mm)\",\n                 y = \"Culmen Depth (mm)\",\n                 color = \"Species\",\n                 hover_name = \"Species\",\n                 hover_data = [\"Island\", \"Sex\"],\n                 size = \"Body Mass (g)\",\n                 size_max = 8,\n                 width = 500,\n                 height = 300,\n                opacity = 0.5,\n                facet_col=\"Sex\")\n\nfig.update_layout(margin={\"r\":0, \"t\":50, \"l\":0, \"b\":0})\n\nfig.show()\n\n\n\n\n\n\n\nWe have now explored two different ways to work with scatterplots. However, these two plots are both in 2D and only compare two pieces of recorded data in their visualizations. Through Plotly, we can explore plots that compare three different types of measurements. This means we are making 3D scatterplot graphes! For our example, we will keep analyzing both culmen depth and culmen length but now will also incorporate body mass measurements. Luckily for us, the format of our customizations is very similar. Instead, we use a slightly different call that designates that this is a 3-dimensional plot. Run the code block below to see the 3D scatterplot.\n\nfig = px.scatter_3d(penguins,\n                    x = \"Body Mass (g)\",\n                    y = \"Culmen Length (mm)\",\n                    z = \"Culmen Depth (mm)\",\n                    color = \"Species\",\n                    opacity = 0.5)\n\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()\n\n\n\n\nThank you for reading! Good luck making your visualizations with Plotly!"
  },
  {
    "objectID": "posts/HW0-Data Visualization/index.html#using-the-palmer-penguins-data-set",
    "href": "posts/HW0-Data Visualization/index.html#using-the-palmer-penguins-data-set",
    "title": "Data Visualization",
    "section": "",
    "text": "There are many different ways to model and display a set of data. Using the Plotly library, we have the ability to make histographes, boxplots, and more. Plotly makes graphing and modelling data sets very simple and straighforward. In general, you start with calling the type of figure you would like to create and then manually selecting which customization you need for the specific plot."
  },
  {
    "objectID": "posts/HW0-Data Visualization/index.html#scatterplots",
    "href": "posts/HW0-Data Visualization/index.html#scatterplots",
    "title": "Data Visualization",
    "section": "",
    "text": "For simplicity sake, today we will start with developing scatterplots. Before we start making our graph, we must download and organize our data. The easiest way to complete this step is by using panda operations as seen below. Today, we will be using the Palmer Penguin data set that analyzes the differences between three different species of penguins. In order to use this data sheet, we must ensure that we have the file downloaded to the same folder as our Jupyter Notebook. Please run the code cell below to upload the needed data.\n\nimport pandas as pd\nfilename = \"palmer_penguins.csv\"\npenguins = pd.read_csv(filename)\npenguins = penguins.dropna(subset = [\"Body Mass (g)\", \"Sex\"])\npenguins[\"Species\"] = penguins[\"Species\"].str.split().str.get(0)\npenguins = penguins[penguins[\"Sex\"] != \".\"]\n\ncols = [\"Species\", \"Island\", \"Sex\", \"Culmen Length (mm)\", \"Culmen Depth (mm)\", \"Flipper Length (mm)\", \"Body Mass (g)\"]\npenguins = penguins[cols]\n\nAfter we have downloaded our data set, we must import Plotly in order to make our visualizations. Plotly is a useful tool that can be used to create different types of graphs.\n\nimport plotly\n\nNext, we will create a visualization labeled “fig” and use our Plotly commands to organize our data. For this plot, we will see how the length and depth of the culmen vary for different species of penguins. The culmen describes the upper ridge of a penguin’s bill. Researches describe the culmen using depth and length.\nWe use the second and third lines of code to make the final plot visible to a blog user. If you are just planning on creating figures in your notebook, please only use the first line to import the necessary tools to create and customize the plot. We call our scatterplot in the fifth line of code. In the event that you are making a different type of plot, you would set “fig” equal to a different keyword. Within our “()” we will label our x and y axis, change dot color based on the species of penguin, and designate the size of the graph.\nIn the second to last line of code, we add extra customizations to the layout of the plot itself. By using these commands, we can decrease the amount of whitespace of our graph. Finally, we can see our final scatterplot using the last line of code.\n\nfrom plotly import express as px\nimport plotly.io as pio\npio.renderers.default='iframe'\n\nfig = px.scatter(data_frame = penguins,\n                 x = \"Culmen Length (mm)\",\n                 y = \"Culmen Depth (mm)\",\n                 color = \"Species\",\n                 width = 500,\n                 height = 300,\n                )\n\n\nfig.update_layout(margin={\"r\":0, \"t\":0, \"l\":0, \"b\":0})\n\nfig.show()\n \n\n\n\n\nIn all, scatterplots through Plotly are extremely customizable and only require basic calls. Plotly can be used for many different data sets and model many different ideas in a variety of forms."
  },
  {
    "objectID": "posts/HW0-Data Visualization/index.html#scatterplots-with-facets",
    "href": "posts/HW0-Data Visualization/index.html#scatterplots-with-facets",
    "title": "Data Visualization",
    "section": "",
    "text": "Plotly also has the ability to create more detailed scatterplots. For example, we can create facets within our scatterplots. Facets are smaller scatterplots that can add additional details to our visualizations. Similar to our above scatterplot, we will be comparing culmen measurements amoungest different species of penguins. However, we will further our understanding by creating facets that show the recorded culmen data in specific plots for female and male penguins.\nWe set up our plot in a relatively similar way to the demonstration above. The extra customizations will allow our graph to appear in two smaller sets.\n\nfig = px.scatter(data_frame = penguins,\n                 x = \"Culmen Length (mm)\",\n                 y = \"Culmen Depth (mm)\",\n                 color = \"Species\",\n                 hover_name = \"Species\",\n                 hover_data = [\"Island\", \"Sex\"],\n                 size = \"Body Mass (g)\",\n                 size_max = 8,\n                 width = 500,\n                 height = 300,\n                opacity = 0.5,\n                facet_col=\"Sex\")\n\nfig.update_layout(margin={\"r\":0, \"t\":50, \"l\":0, \"b\":0})\n\nfig.show()"
  },
  {
    "objectID": "posts/HW0-Data Visualization/index.html#d-scatterplots",
    "href": "posts/HW0-Data Visualization/index.html#d-scatterplots",
    "title": "Data Visualization",
    "section": "",
    "text": "We have now explored two different ways to work with scatterplots. However, these two plots are both in 2D and only compare two pieces of recorded data in their visualizations. Through Plotly, we can explore plots that compare three different types of measurements. This means we are making 3D scatterplot graphes! For our example, we will keep analyzing both culmen depth and culmen length but now will also incorporate body mass measurements. Luckily for us, the format of our customizations is very similar. Instead, we use a slightly different call that designates that this is a 3-dimensional plot. Run the code block below to see the 3D scatterplot.\n\nfig = px.scatter_3d(penguins,\n                    x = \"Body Mass (g)\",\n                    y = \"Culmen Length (mm)\",\n                    z = \"Culmen Depth (mm)\",\n                    color = \"Species\",\n                    opacity = 0.5)\n\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()\n\n\n\n\nThank you for reading! Good luck making your visualizations with Plotly!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "myblog",
    "section": "",
    "text": "Data Wrangling and Visualization\n\n\n\n\n\n\nHomework\n\n\ncode\n\n\nWeek 1\n\n\n\n\n\n\n\n\n\nJan 30, 2024\n\n\nIsabella Woulfe\n\n\n\n\n\n\n\n\n\n\n\n\nData Visualization\n\n\n\n\n\n\nHomework\n\n\ncode\n\n\nWeek 0\n\n\n\n\n\n\n\n\n\nJan 22, 2024\n\n\nIsabella Woulfe\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 20, 2024\n\n\nIsabella Woulfe\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJan 17, 2024\n\n\nIsabella Woulfe\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Isabella Woulfe",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/HW 1/index.html",
    "href": "posts/HW 1/index.html",
    "title": "Data Wrangling and Visualization",
    "section": "",
    "text": "Today, we will be reviewing how to create interesting and interative data sets with the NOAA climate data. The data set that we will be using has a list of countries, different station names, recorded temperatures for every month of the year and more. By analyzing and organzing our data sets efficiently, we will be able to create interesting visualizations and use them to answer a variety of questions.\nBefore we start, we must download the necessary packages to create our database. Please run the code cell bellow to import Pandas, Numpy and SQL.\n\nimport pandas as pd\nimport numpy as np\nimport sqlite3\n\nNow that we have our packages, we will start importing three different datasets. We must save these csv files in the same folder as our Jupyter Notebook in order to use them here. In the following code cells, we will use the call stations.head() to show the first five rows of our data in a table. This step makes it easy for us to ensure that there was no problems when uploading our datasets. Please run the following code cells and then we can get started building our database.\n\nfilename = \"station-metadata.csv\"\nstations = pd.read_csv(filename)\nstations.head()\n\n\n\n\n\n\n\n\nID\nLATITUDE\nLONGITUDE\nSTNELEV\nNAME\n\n\n\n\n0\nACW00011604\n57.7667\n11.8667\n18.0\nSAVE\n\n\n1\nAE000041196\n25.3330\n55.5170\n34.0\nSHARJAH_INTER_AIRP\n\n\n2\nAEM00041184\n25.6170\n55.9330\n31.0\nRAS_AL_KHAIMAH_INTE\n\n\n3\nAEM00041194\n25.2550\n55.3640\n10.4\nDUBAI_INTL\n\n\n4\nAEM00041216\n24.4300\n54.4700\n3.0\nABU_DHABI_BATEEN_AIR\n\n\n\n\n\n\n\n\nfilename = \"country-codes.csv\"\ncountries = pd.read_csv(filename)\ncountries.head()\n\n\n\n\n\n\n\n\nFIPS 10-4\nISO 3166\nName\n\n\n\n\n0\nAF\nAF\nAfghanistan\n\n\n1\nAX\n-\nAkrotiri\n\n\n2\nAL\nAL\nAlbania\n\n\n3\nAG\nDZ\nAlgeria\n\n\n4\nAQ\nAS\nAmerican Samoa\n\n\n\n\n\n\n\n\nfilename = \"temps.csv\"\ntemperatures = pd.read_csv(filename)\ntemperatures.head()\n\n\n\n\n\n\n\n\nID\nYear\nVALUE1\nVALUE2\nVALUE3\nVALUE4\nVALUE5\nVALUE6\nVALUE7\nVALUE8\nVALUE9\nVALUE10\nVALUE11\nVALUE12\n\n\n\n\n0\nACW00011604\n1961\n-89.0\n236.0\n472.0\n773.0\n1128.0\n1599.0\n1570.0\n1481.0\n1413.0\n1174.0\n510.0\n-39.0\n\n\n1\nACW00011604\n1962\n113.0\n85.0\n-154.0\n635.0\n908.0\n1381.0\n1510.0\n1393.0\n1163.0\n994.0\n323.0\n-126.0\n\n\n2\nACW00011604\n1963\n-713.0\n-553.0\n-99.0\n541.0\n1224.0\n1627.0\n1620.0\n1596.0\n1332.0\n940.0\n566.0\n-108.0\n\n\n3\nACW00011604\n1964\n62.0\n-85.0\n55.0\n738.0\n1219.0\n1442.0\n1506.0\n1557.0\n1221.0\n788.0\n546.0\n112.0\n\n\n4\nACW00011604\n1965\n44.0\n-105.0\n38.0\n590.0\n987.0\n1500.0\n1487.0\n1477.0\n1377.0\n974.0\n31.0\n-178.0\n\n\n\n\n\n\n\n\n\n\nNow that we have uploaded the three necessary datasets, we will create a new data frame that can be used to organize the specific data we want to use. We will use SQL to pull from our three data sets to craft out database.\n\nconn = sqlite3.connect(\"temps.db\")\ndf_iter = pd.read_csv(\"temps.csv\", chunksize = 100000)\ndf = df_iter.__next__()\ndef prepare_df(df):\n    df = df.set_index(keys=[\"ID\", \"Year\"])\n    df = df.stack()\n    df = df.reset_index()\n    df = df.rename(columns = {\"level_2\"  : \"Month\" , 0 : \"Temp\"})\n    df[\"Month\"] = df[\"Month\"].str[5:].astype(int)\n    df[\"Temp\"]  = df[\"Temp\"] / 100\n    return(df)\n\n\ndf_iter = pd.read_csv(\"temps.csv\", chunksize = 100000)\nfor i, df in enumerate(df_iter):\n    df = prepare_df(df)\n    df.to_sql(\"temperatures\", conn, if_exists = \"replace\" if i == 0 else \"append\", index = False)\n\n\nurl = \"station-metadata.csv\"\nstations = pd.read_csv(url)\nstations.to_sql(\"stations\", conn, if_exists = \"replace\", index=False)\n\n27585\n\n\n\nurl = \"country-codes.csv\"\ncountries = pd.read_csv(url)\ncountries.to_sql(\"countries\", conn, if_exists = \"replace\", index=False)\n\n279\n\n\n\ncursor = conn.cursor()\ncursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\nprint(cursor.fetchall())\n\n[('temperatures',), ('country',), ('stations',), ('countries',)]\n\n\nWe now have downloaded all of our different data sets into our folder. We will now use the following commands to create tables. We should see three seperate table headings in our output.\n\ncursor.execute(\"SELECT sql FROM sqlite_master WHERE type='table';\")\n\nfor result in cursor.fetchall():\n    print(result[0])\n\nCREATE TABLE \"temperatures\" (\n\"ID\" TEXT,\n  \"Year\" INTEGER,\n  \"Month\" INTEGER,\n  \"Temp\" REAL\n)\nCREATE TABLE \"country\" (\n\"FIPS 10-4\" TEXT,\n  \"ISO 3166\" TEXT,\n  \"Name\" TEXT\n)\nCREATE TABLE \"stations\" (\n\"ID\" TEXT,\n  \"LATITUDE\" REAL,\n  \"LONGITUDE\" REAL,\n  \"STNELEV\" REAL,\n  \"NAME\" TEXT\n)\nCREATE TABLE \"countries\" (\n\"FIPS 10-4\" TEXT,\n  \"ISO 3166\" TEXT,\n  \"Name\" TEXT\n)\n\n\nWe will fill our database using a function in a seperate Python file. From this file, we will import our function and as a result our database. This function requires us to use SQL keywords (written in all capital letters) in order to easily combine different sorts of data into one whole set.\n\nfrom climate_database import query_climate_database\nimport inspect\nprint(inspect.getsource(query_climate_database))\n\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    conn = sqlite3.connect(db_file)\n    query = f'''\n        SELECT s.NAME, s.LATITUDE, s.LONGITUDE, c.NAME AS Country, t.Year, t.Month, t.Temp\n        FROM temperatures t\n        LEFT JOIN stations s ON t.ID = s.id\n        LEFT JOIN countries c ON t.ID LIKE c.\"FIPS 10-4\" || '%'\n        WHERE c.Name = '{country}' AND t.Month = {month} AND t.Year BETWEEN {year_begin} AND {year_end}\n\n'''\n    result_df = pd.read_sql_query(query, conn)\n    conn.close()\n    return result_df\n\n\n\nIt is very important that we test our code as we go so that we can be certain we have not encountered any errors. The code cell below will create a database for temperatures in India during January between the years of 1980 and 2020. Please run the cell below to show that we correctly implemented our database.\n\n#test case for our query function \nquery_climate_database(db_file = \"temps.db\", \n                       country = \"India\", \n                       year_begin = 1980, \n                       year_end = 2020, \n                       month = 1)\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nCountry\nYear\nMonth\nTemp\n\n\n\n\n0\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1980\n1\n23.48\n\n\n1\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1981\n1\n24.57\n\n\n2\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1982\n1\n24.19\n\n\n3\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1983\n1\n23.51\n\n\n4\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1984\n1\n24.81\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3147\nDARJEELING\n27.050\n88.270\nIndia\n1983\n1\n5.10\n\n\n3148\nDARJEELING\n27.050\n88.270\nIndia\n1986\n1\n6.90\n\n\n3149\nDARJEELING\n27.050\n88.270\nIndia\n1994\n1\n8.10\n\n\n3150\nDARJEELING\n27.050\n88.270\nIndia\n1995\n1\n5.60\n\n\n3151\nDARJEELING\n27.050\n88.270\nIndia\n1997\n1\n5.70\n\n\n\n\n3152 rows × 7 columns\n\n\n\nAs our database for India matches the sample, we have correctly created our database!\n\n\n\nNow that we have all our data from our three sets organized, we can use them to answer interesting questions. Visualizations are a great way to display data as they are super versatile and easy to read. We will use Plotly to create our data sets. Please import the Plotly package below.\n\nfrom plotly import express as px\n\n\nimport plotly.io as pio\npio.renderers.default=\"iframe\"\n\nLet’s get started with our first question.\nHow does the average yearly change in temperature vary within a given country?\nThe best way to tackle this question is through creating a geographic scatter function. This figure will appear as a map but will mark specific stations in a given country and share their temperature measurements. We will start by creating a function called tenperature_coefficient_plot(). Please follow the code written below to create our first visualization. We must be sure to include the necessary parameters and be as detailed as possible with our plots.\n\ndef temperature_coefficient_plot(db_file, country, year_begin, year_end, month, min_obs, **kwargs):\n    df = query_climate_database(db_file, country, year_begin, year_end, month)\n    df = df[df.groupby('NAME')['Year'].transform('count') &gt;= min_obs]\n\n    def temperature_average(data):\n        X = data['Year']\n        y = data['Temp']\n        \n        average = np.polyfit(X, y, deg=1)[0]\n        \n        return average\n\n    coefs = df.groupby('NAME').apply(temperature_average).reset_index()\n    coefs.columns = ['NAME', 'YearlyChange']\n\n    df = pd.merge(df, coefs, on='NAME')\n\n    fig = px.scatter_mapbox(df, \n                            lat='LATITUDE', \n                            lon='LONGITUDE',\n                            color='YearlyChange',\n                            hover_data = {'NAME' : True, 'YearlyChange': ':.3f'},\n                            labels = {'YearlyChange': 'Estimated Yearly Increase (Celsius)'}, \n                            title = f\"Estimates of Yearly Increase in Temperature in {pd.to_datetime(month, format='%m').month_name()} for stations in {country}, {year_begin}-{year_end}\",\n                            **kwargs)\n    fig.update_layout(mapbox_style=\"open-street-map\")\n    return fig\n\nWe will now use the following test case of India in January during 1980-2020 to test our function. As you can see, we will create a figure that appears as an interactive map that easily displays the answer to our posed question\n\n#test case \ncolor_map = px.colors.diverging.RdGy_r # choose a colormap\n\nfig = temperature_coefficient_plot(\"temps.db\", \"India\", 1980, 2020, 1, \n                                   min_obs=10,\n                                   zoom=2,\n                                   mapbox_style=\"carto-positron\",\n                                   color_continuous_scale=color_map)\n\nfig.show()\n\n\n\n\nNow, we can answer our question! For our chosen country of India, we can see that India has not experienced huge increases in temperature during the month of Januray over the period of forty years. Nevertheless, there are some stations along the coasts and borders that have seen significant increases in temperature.\n\n\n\nWhile we are programming, we want to ask questions that we can answer using our models. By asking these questions, we can connect our data sets to real world scenarios.\nFor our next question, let’s ask which regions of the world have the highest concentration of stations recording temperature data?\nThe best way to approach this question is to create a heatmap using our knowledge of Plotly. We can start by defining the following function. We can create the figure using specific columns from our database.\n\ndef temperature_coefficient_heatmap(db_file, country, year_begin, year_end, month, min_obs, **kwargs):\n    df = query_climate_database(db_file, country, year_begin, year_end, month)\n    df = df[df.groupby('NAME')['Year'].transform('count') &gt;= min_obs]\n\n    def temperature_average(data):\n        X = data['Year']\n        y = data['Temp']\n        \n        average = np.polyfit(X, y, deg=1)[0]\n        \n        return average\n\n    coefs = df.groupby('NAME').apply(temperature_average).reset_index()\n    coefs.columns = ['NAME', 'YearlyChange']\n\n    df = pd.merge(df, coefs, on='NAME')\n\n   \n#outputs our figure\nfig = px.density_mapbox(stations,\n                        lat = \"LATITUDE\",\n                        lon = \"LONGITUDE\",\n                        hover_data = {'NAME' : True},\n                        radius = 1,\n                        zoom = 0,\n                        height = 300)\n\nfig.update_layout(mapbox_style=\"carto-positron\")\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()\n\n\n\n\nNow that we have our plot, it is important that we understand what it is telling us. The lighter the color gets (or yellower) means that there is a higher concentration of stations recording these temperatures in our data set. In regions with only a few stations, we only note a handful of dots spread around the area.\nIn response to our question, it seems that the United States and parts of Europe have the highest concentration of stations.\nFinally, let’s create one more visualization and learn more about temperature using our data sets. During a twenty-year period, which part of Italy experienced higher average temperatures during the month of August: North Italy, Central Italy, or South Italy?\nAs someone who has lived in Italy, I am very aware of the different lifestyles of the people in each of these three regions. Moreover, I would like to inquire whether climate has played a role in these cultural differences.\nOnce again, I have decided to use a scatterplot to answer my question. However, this scatterplot will differ from the one above as it analyzes the average temperature of each station rather than the change in temperature. Please see the code below.\n\ndef regional_difference_plot(db_file, country, year_begin, year_end, month, min_obs, **kwargs):\n    df = query_climate_database(db_file, country, year_begin, year_end, month)\n    df = df[df.groupby('NAME')['Temp'].transform('count') &gt;= min_obs]\n\n    def temperature_average(df):\n        average = np.mean(df['Temp'])\n        \n        return average\n\n    coefs = df.groupby('NAME').apply(temperature_average).reset_index()\n    coefs.columns = ['NAME', 'Average Temperature']\n\n    df = pd.merge(df, coefs, on='NAME')\n\n    fig = px.scatter_mapbox(df, \n                            lat='LATITUDE', \n                            lon='LONGITUDE',\n                            color='Average Temperature',\n                            hover_data = {'NAME' : True, 'Average Temperature': ':.3f'},\n                            labels = {'Average Temperature': 'Average Temperature (Celsius)'}, \n                            title = f\"Temperatures in {pd.to_datetime(month, format='%m').month_name()} for stations in {country}, {year_begin}-{year_end}\",\n                            **kwargs)\n    fig.update_layout(mapbox_style=\"open-street-map\")\n    return fig\n\nAlthough we can apply this function to any country, month, or year, we will look at Italy in August over a twenty year period to develop our conclusion.\n\n#test case \ncolor_map = px.colors.diverging.RdGy_r # choose a colormap\n\nfig = regional_difference_plot(\"temps.db\", \"Italy\", 1980, 2000, 8, \n                                   min_obs=10,\n                                   zoom=2,\n                                   mapbox_style=\"carto-positron\",\n                                   color_continuous_scale=color_map)\n\nfig.show()\n\n\n\n\nIn our plot above, we can see that South Italian stations have the points with the deepest red. This means that the South of Italy experienced the highest average temperatures compared to both the North and Central regions. I believe that this is very fitting considering the lifestyle and daily practices of people who reside in Southern Italy.\nThus, we have thoroughly reviewed how to create databases and make visualizations using our temperature data sets. Thank you for reading!"
  },
  {
    "objectID": "posts/HW 1/index.html#introduction",
    "href": "posts/HW 1/index.html#introduction",
    "title": "Data Wrangling and Visualization",
    "section": "",
    "text": "Today, we will be reviewing how to create interesting and interative data sets with the NOAA climate data. The data set that we will be using has a list of countries, different station names, recorded temperatures for every month of the year and more. By analyzing and organzing our data sets efficiently, we will be able to create interesting visualizations and use them to answer a variety of questions.\nBefore we start, we must download the necessary packages to create our database. Please run the code cell bellow to import Pandas, Numpy and SQL.\n\nimport pandas as pd\nimport numpy as np\nimport sqlite3\n\nNow that we have our packages, we will start importing three different datasets. We must save these csv files in the same folder as our Jupyter Notebook in order to use them here. In the following code cells, we will use the call stations.head() to show the first five rows of our data in a table. This step makes it easy for us to ensure that there was no problems when uploading our datasets. Please run the following code cells and then we can get started building our database.\n\nfilename = \"station-metadata.csv\"\nstations = pd.read_csv(filename)\nstations.head()\n\n\n\n\n\n\n\n\nID\nLATITUDE\nLONGITUDE\nSTNELEV\nNAME\n\n\n\n\n0\nACW00011604\n57.7667\n11.8667\n18.0\nSAVE\n\n\n1\nAE000041196\n25.3330\n55.5170\n34.0\nSHARJAH_INTER_AIRP\n\n\n2\nAEM00041184\n25.6170\n55.9330\n31.0\nRAS_AL_KHAIMAH_INTE\n\n\n3\nAEM00041194\n25.2550\n55.3640\n10.4\nDUBAI_INTL\n\n\n4\nAEM00041216\n24.4300\n54.4700\n3.0\nABU_DHABI_BATEEN_AIR\n\n\n\n\n\n\n\n\nfilename = \"country-codes.csv\"\ncountries = pd.read_csv(filename)\ncountries.head()\n\n\n\n\n\n\n\n\nFIPS 10-4\nISO 3166\nName\n\n\n\n\n0\nAF\nAF\nAfghanistan\n\n\n1\nAX\n-\nAkrotiri\n\n\n2\nAL\nAL\nAlbania\n\n\n3\nAG\nDZ\nAlgeria\n\n\n4\nAQ\nAS\nAmerican Samoa\n\n\n\n\n\n\n\n\nfilename = \"temps.csv\"\ntemperatures = pd.read_csv(filename)\ntemperatures.head()\n\n\n\n\n\n\n\n\nID\nYear\nVALUE1\nVALUE2\nVALUE3\nVALUE4\nVALUE5\nVALUE6\nVALUE7\nVALUE8\nVALUE9\nVALUE10\nVALUE11\nVALUE12\n\n\n\n\n0\nACW00011604\n1961\n-89.0\n236.0\n472.0\n773.0\n1128.0\n1599.0\n1570.0\n1481.0\n1413.0\n1174.0\n510.0\n-39.0\n\n\n1\nACW00011604\n1962\n113.0\n85.0\n-154.0\n635.0\n908.0\n1381.0\n1510.0\n1393.0\n1163.0\n994.0\n323.0\n-126.0\n\n\n2\nACW00011604\n1963\n-713.0\n-553.0\n-99.0\n541.0\n1224.0\n1627.0\n1620.0\n1596.0\n1332.0\n940.0\n566.0\n-108.0\n\n\n3\nACW00011604\n1964\n62.0\n-85.0\n55.0\n738.0\n1219.0\n1442.0\n1506.0\n1557.0\n1221.0\n788.0\n546.0\n112.0\n\n\n4\nACW00011604\n1965\n44.0\n-105.0\n38.0\n590.0\n987.0\n1500.0\n1487.0\n1477.0\n1377.0\n974.0\n31.0\n-178.0"
  },
  {
    "objectID": "posts/HW 1/index.html#creating-and-organizing-our-database",
    "href": "posts/HW 1/index.html#creating-and-organizing-our-database",
    "title": "Data Wrangling and Visualization",
    "section": "",
    "text": "Now that we have uploaded the three necessary datasets, we will create a new data frame that can be used to organize the specific data we want to use. We will use SQL to pull from our three data sets to craft out database.\n\nconn = sqlite3.connect(\"temps.db\")\ndf_iter = pd.read_csv(\"temps.csv\", chunksize = 100000)\ndf = df_iter.__next__()\ndef prepare_df(df):\n    df = df.set_index(keys=[\"ID\", \"Year\"])\n    df = df.stack()\n    df = df.reset_index()\n    df = df.rename(columns = {\"level_2\"  : \"Month\" , 0 : \"Temp\"})\n    df[\"Month\"] = df[\"Month\"].str[5:].astype(int)\n    df[\"Temp\"]  = df[\"Temp\"] / 100\n    return(df)\n\n\ndf_iter = pd.read_csv(\"temps.csv\", chunksize = 100000)\nfor i, df in enumerate(df_iter):\n    df = prepare_df(df)\n    df.to_sql(\"temperatures\", conn, if_exists = \"replace\" if i == 0 else \"append\", index = False)\n\n\nurl = \"station-metadata.csv\"\nstations = pd.read_csv(url)\nstations.to_sql(\"stations\", conn, if_exists = \"replace\", index=False)\n\n27585\n\n\n\nurl = \"country-codes.csv\"\ncountries = pd.read_csv(url)\ncountries.to_sql(\"countries\", conn, if_exists = \"replace\", index=False)\n\n279\n\n\n\ncursor = conn.cursor()\ncursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\nprint(cursor.fetchall())\n\n[('temperatures',), ('country',), ('stations',), ('countries',)]\n\n\nWe now have downloaded all of our different data sets into our folder. We will now use the following commands to create tables. We should see three seperate table headings in our output.\n\ncursor.execute(\"SELECT sql FROM sqlite_master WHERE type='table';\")\n\nfor result in cursor.fetchall():\n    print(result[0])\n\nCREATE TABLE \"temperatures\" (\n\"ID\" TEXT,\n  \"Year\" INTEGER,\n  \"Month\" INTEGER,\n  \"Temp\" REAL\n)\nCREATE TABLE \"country\" (\n\"FIPS 10-4\" TEXT,\n  \"ISO 3166\" TEXT,\n  \"Name\" TEXT\n)\nCREATE TABLE \"stations\" (\n\"ID\" TEXT,\n  \"LATITUDE\" REAL,\n  \"LONGITUDE\" REAL,\n  \"STNELEV\" REAL,\n  \"NAME\" TEXT\n)\nCREATE TABLE \"countries\" (\n\"FIPS 10-4\" TEXT,\n  \"ISO 3166\" TEXT,\n  \"Name\" TEXT\n)\n\n\nWe will fill our database using a function in a seperate Python file. From this file, we will import our function and as a result our database. This function requires us to use SQL keywords (written in all capital letters) in order to easily combine different sorts of data into one whole set.\n\nfrom climate_database import query_climate_database\nimport inspect\nprint(inspect.getsource(query_climate_database))\n\ndef query_climate_database(db_file, country, year_begin, year_end, month):\n    conn = sqlite3.connect(db_file)\n    query = f'''\n        SELECT s.NAME, s.LATITUDE, s.LONGITUDE, c.NAME AS Country, t.Year, t.Month, t.Temp\n        FROM temperatures t\n        LEFT JOIN stations s ON t.ID = s.id\n        LEFT JOIN countries c ON t.ID LIKE c.\"FIPS 10-4\" || '%'\n        WHERE c.Name = '{country}' AND t.Month = {month} AND t.Year BETWEEN {year_begin} AND {year_end}\n\n'''\n    result_df = pd.read_sql_query(query, conn)\n    conn.close()\n    return result_df\n\n\n\nIt is very important that we test our code as we go so that we can be certain we have not encountered any errors. The code cell below will create a database for temperatures in India during January between the years of 1980 and 2020. Please run the cell below to show that we correctly implemented our database.\n\n#test case for our query function \nquery_climate_database(db_file = \"temps.db\", \n                       country = \"India\", \n                       year_begin = 1980, \n                       year_end = 2020, \n                       month = 1)\n\n\n\n\n\n\n\n\nNAME\nLATITUDE\nLONGITUDE\nCountry\nYear\nMonth\nTemp\n\n\n\n\n0\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1980\n1\n23.48\n\n\n1\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1981\n1\n24.57\n\n\n2\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1982\n1\n24.19\n\n\n3\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1983\n1\n23.51\n\n\n4\nPBO_ANANTAPUR\n14.583\n77.633\nIndia\n1984\n1\n24.81\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3147\nDARJEELING\n27.050\n88.270\nIndia\n1983\n1\n5.10\n\n\n3148\nDARJEELING\n27.050\n88.270\nIndia\n1986\n1\n6.90\n\n\n3149\nDARJEELING\n27.050\n88.270\nIndia\n1994\n1\n8.10\n\n\n3150\nDARJEELING\n27.050\n88.270\nIndia\n1995\n1\n5.60\n\n\n3151\nDARJEELING\n27.050\n88.270\nIndia\n1997\n1\n5.70\n\n\n\n\n3152 rows × 7 columns\n\n\n\nAs our database for India matches the sample, we have correctly created our database!"
  },
  {
    "objectID": "posts/HW 1/index.html#developing-visualizations-from-our-database",
    "href": "posts/HW 1/index.html#developing-visualizations-from-our-database",
    "title": "Data Wrangling and Visualization",
    "section": "",
    "text": "Now that we have all our data from our three sets organized, we can use them to answer interesting questions. Visualizations are a great way to display data as they are super versatile and easy to read. We will use Plotly to create our data sets. Please import the Plotly package below.\n\nfrom plotly import express as px\n\n\nimport plotly.io as pio\npio.renderers.default=\"iframe\"\n\nLet’s get started with our first question.\nHow does the average yearly change in temperature vary within a given country?\nThe best way to tackle this question is through creating a geographic scatter function. This figure will appear as a map but will mark specific stations in a given country and share their temperature measurements. We will start by creating a function called tenperature_coefficient_plot(). Please follow the code written below to create our first visualization. We must be sure to include the necessary parameters and be as detailed as possible with our plots.\n\ndef temperature_coefficient_plot(db_file, country, year_begin, year_end, month, min_obs, **kwargs):\n    df = query_climate_database(db_file, country, year_begin, year_end, month)\n    df = df[df.groupby('NAME')['Year'].transform('count') &gt;= min_obs]\n\n    def temperature_average(data):\n        X = data['Year']\n        y = data['Temp']\n        \n        average = np.polyfit(X, y, deg=1)[0]\n        \n        return average\n\n    coefs = df.groupby('NAME').apply(temperature_average).reset_index()\n    coefs.columns = ['NAME', 'YearlyChange']\n\n    df = pd.merge(df, coefs, on='NAME')\n\n    fig = px.scatter_mapbox(df, \n                            lat='LATITUDE', \n                            lon='LONGITUDE',\n                            color='YearlyChange',\n                            hover_data = {'NAME' : True, 'YearlyChange': ':.3f'},\n                            labels = {'YearlyChange': 'Estimated Yearly Increase (Celsius)'}, \n                            title = f\"Estimates of Yearly Increase in Temperature in {pd.to_datetime(month, format='%m').month_name()} for stations in {country}, {year_begin}-{year_end}\",\n                            **kwargs)\n    fig.update_layout(mapbox_style=\"open-street-map\")\n    return fig\n\nWe will now use the following test case of India in January during 1980-2020 to test our function. As you can see, we will create a figure that appears as an interactive map that easily displays the answer to our posed question\n\n#test case \ncolor_map = px.colors.diverging.RdGy_r # choose a colormap\n\nfig = temperature_coefficient_plot(\"temps.db\", \"India\", 1980, 2020, 1, \n                                   min_obs=10,\n                                   zoom=2,\n                                   mapbox_style=\"carto-positron\",\n                                   color_continuous_scale=color_map)\n\nfig.show()\n\n\n\n\nNow, we can answer our question! For our chosen country of India, we can see that India has not experienced huge increases in temperature during the month of Januray over the period of forty years. Nevertheless, there are some stations along the coasts and borders that have seen significant increases in temperature."
  },
  {
    "objectID": "posts/HW 1/index.html#other-forms-of-visualizations-heatmaps-more-scatter-plots",
    "href": "posts/HW 1/index.html#other-forms-of-visualizations-heatmaps-more-scatter-plots",
    "title": "Data Wrangling and Visualization",
    "section": "",
    "text": "While we are programming, we want to ask questions that we can answer using our models. By asking these questions, we can connect our data sets to real world scenarios.\nFor our next question, let’s ask which regions of the world have the highest concentration of stations recording temperature data?\nThe best way to approach this question is to create a heatmap using our knowledge of Plotly. We can start by defining the following function. We can create the figure using specific columns from our database.\n\ndef temperature_coefficient_heatmap(db_file, country, year_begin, year_end, month, min_obs, **kwargs):\n    df = query_climate_database(db_file, country, year_begin, year_end, month)\n    df = df[df.groupby('NAME')['Year'].transform('count') &gt;= min_obs]\n\n    def temperature_average(data):\n        X = data['Year']\n        y = data['Temp']\n        \n        average = np.polyfit(X, y, deg=1)[0]\n        \n        return average\n\n    coefs = df.groupby('NAME').apply(temperature_average).reset_index()\n    coefs.columns = ['NAME', 'YearlyChange']\n\n    df = pd.merge(df, coefs, on='NAME')\n\n   \n#outputs our figure\nfig = px.density_mapbox(stations,\n                        lat = \"LATITUDE\",\n                        lon = \"LONGITUDE\",\n                        hover_data = {'NAME' : True},\n                        radius = 1,\n                        zoom = 0,\n                        height = 300)\n\nfig.update_layout(mapbox_style=\"carto-positron\")\nfig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\nfig.show()\n\n\n\n\nNow that we have our plot, it is important that we understand what it is telling us. The lighter the color gets (or yellower) means that there is a higher concentration of stations recording these temperatures in our data set. In regions with only a few stations, we only note a handful of dots spread around the area.\nIn response to our question, it seems that the United States and parts of Europe have the highest concentration of stations.\nFinally, let’s create one more visualization and learn more about temperature using our data sets. During a twenty-year period, which part of Italy experienced higher average temperatures during the month of August: North Italy, Central Italy, or South Italy?\nAs someone who has lived in Italy, I am very aware of the different lifestyles of the people in each of these three regions. Moreover, I would like to inquire whether climate has played a role in these cultural differences.\nOnce again, I have decided to use a scatterplot to answer my question. However, this scatterplot will differ from the one above as it analyzes the average temperature of each station rather than the change in temperature. Please see the code below.\n\ndef regional_difference_plot(db_file, country, year_begin, year_end, month, min_obs, **kwargs):\n    df = query_climate_database(db_file, country, year_begin, year_end, month)\n    df = df[df.groupby('NAME')['Temp'].transform('count') &gt;= min_obs]\n\n    def temperature_average(df):\n        average = np.mean(df['Temp'])\n        \n        return average\n\n    coefs = df.groupby('NAME').apply(temperature_average).reset_index()\n    coefs.columns = ['NAME', 'Average Temperature']\n\n    df = pd.merge(df, coefs, on='NAME')\n\n    fig = px.scatter_mapbox(df, \n                            lat='LATITUDE', \n                            lon='LONGITUDE',\n                            color='Average Temperature',\n                            hover_data = {'NAME' : True, 'Average Temperature': ':.3f'},\n                            labels = {'Average Temperature': 'Average Temperature (Celsius)'}, \n                            title = f\"Temperatures in {pd.to_datetime(month, format='%m').month_name()} for stations in {country}, {year_begin}-{year_end}\",\n                            **kwargs)\n    fig.update_layout(mapbox_style=\"open-street-map\")\n    return fig\n\nAlthough we can apply this function to any country, month, or year, we will look at Italy in August over a twenty year period to develop our conclusion.\n\n#test case \ncolor_map = px.colors.diverging.RdGy_r # choose a colormap\n\nfig = regional_difference_plot(\"temps.db\", \"Italy\", 1980, 2000, 8, \n                                   min_obs=10,\n                                   zoom=2,\n                                   mapbox_style=\"carto-positron\",\n                                   color_continuous_scale=color_map)\n\nfig.show()\n\n\n\n\nIn our plot above, we can see that South Italian stations have the points with the deepest red. This means that the South of Italy experienced the highest average temperatures compared to both the North and Central regions. I believe that this is very fitting considering the lifestyle and daily practices of people who reside in Southern Italy.\nThus, we have thoroughly reviewed how to create databases and make visualizations using our temperature data sets. Thank you for reading!"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  }
]